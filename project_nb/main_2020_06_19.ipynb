{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T19:58:34.655860Z",
     "start_time": "2020-06-19T19:58:30.714253Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import calendar\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import requests as rq\n",
    "\n",
    "# for aWhere API\n",
    "from header import AWhereAPI\n",
    "from secret_codes import *\n",
    "\n",
    "api_key = API_KEY\n",
    "api_secret = API_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T19:58:35.574568Z",
     "start_time": "2020-06-19T19:58:34.700277Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create aWhere object\n",
    "aw = AWhereAPI(api_key, api_secret)\n",
    "\n",
    "# To get auth token, encode secret and key\n",
    "sc = aw.encode_secret_and_key(API_KEY, API_SECRET)\n",
    "\n",
    "# Then call auth token\n",
    "token = aw.get_oauth_token(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T19:58:35.653239Z",
     "start_time": "2020-06-19T19:58:35.645265Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for aWhere API call \n",
    "\n",
    "# General endpoint\n",
    "endpt = \"https://api.awhere.com\"\n",
    "\n",
    "# Set up headers: auth and specific header for agronomics data\n",
    "auth_headers = {\"Authorization\": \"Bearer %s\" % token,\n",
    "                \"Content-Type\": 'application/json'}\n",
    "\n",
    "agro_header = {\"Authorization\":  \"Bearer %s\" % token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T19:58:58.831322Z",
     "start_time": "2020-06-19T19:58:58.529341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Load area of interest into gpd\n",
    "\n",
    "# Create path to home\n",
    "home = str(Path.home())\n",
    "\n",
    "# Create path to Siskiyou geojson since csv crashes Jupyter\n",
    "path_to_josephine = os.path.join(\n",
    "    home, \"Desktop\", \"drought-tracker\", \"data\", \"TIGER\", \"josephine.geojson\")\n",
    "\n",
    "# Create df with 1 county (Siskiyou)\n",
    "josephine = gpd.read_file(path_to_josephine)\n",
    "\n",
    "# Convert into CRS\n",
    "josephine = josephine.to_crs(\"EPSG:4236\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T19:59:46.232607Z",
     "start_time": "2020-06-19T19:59:46.220637Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_awhere_grid(aoi, out_crs, calc_crs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    aoi: Geopandas GeoDataFrame\n",
    "        One-element GeoDataFrame containing area over which\n",
    "        to draw grid\n",
    "    \n",
    "    out_crs: numeric string\n",
    "        String of EPSG code for exported GDF\n",
    "    \n",
    "    calc_crs: numeric string\n",
    "        String of EPSG code for CRS used\n",
    "        to calculate grid. CRS must have units of meters\n",
    "        to work with aWhere's API\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame containing 9km x 9km cells\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Reproject aoi to CRS using meters for aWhere grid cells\n",
    "    aoi = aoi.to_crs(f'EPSG:{calc_crs}')\n",
    "    \n",
    "    # Get x and y min and max from total boundaries\n",
    "    xmin, ymin, xmax, ymax = aoi.total_bounds\n",
    "    \n",
    "    # Set side of grid cell to 9 km\n",
    "    side = 9000\n",
    "    \n",
    "    # Create x values for x points for rows\n",
    "    x_range = np.arange(int(np.floor(xmin)), int(np.ceil(xmax)), side)\n",
    "    \n",
    "    # Create y values\n",
    "    y_range = np.arange(int(np.floor(ymin)), int(np.floor(ymax)), side)\n",
    "    \n",
    "    # Create empty list to hold grid cells\n",
    "    polygons = []\n",
    "    \n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            polygons.append(Polygon([(x,y), (x+side, y), (x+side, y+side), (x,y+side)]))\n",
    "            \n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons}, crs=f\"EPSG:{calc_crs}\")\n",
    "    \n",
    "    #grid.set_crs = f'EPSG:{calc_crs}'\n",
    "    \n",
    "    # Convert to out_crs\n",
    "    grid = grid.to_crs(f\"EPSG:{out_crs}\")\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:00:09.175644Z",
     "start_time": "2020-06-19T20:00:08.599397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create grid polygon\n",
    "grid = create_awhere_grid(aoi=josephine,\n",
    "                          out_crs='4236',\n",
    "                          calc_crs='2019')\n",
    "\n",
    "# Add centroid column\n",
    "grid['centroid'] = grid.geometry.apply(lambda poly: poly.centroid)\n",
    "\n",
    "# Check to see if everything looks correct\n",
    "fig, ax = plt.subplots()\n",
    "grid.plot(color=\"none\", linewidth=1, edgecolor='orange', ax=ax, zorder=3)\n",
    "josephine.plot(color='green', zorder=2, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:00:21.048371Z",
     "start_time": "2020-06-19T20:00:21.040392Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_api(lat, lon, start_date, end_date, testing=False):\n",
    "    \n",
    "        # URL to historical agronomics (norms)\n",
    "        hist_ag_url = f\"/v2/agronomics/locations/{lat},{lon}/agronomicvalues/{start_date},{end_date}\"\n",
    "\n",
    "        # Endpoint suffix to get all accumulations\n",
    "        url_append = \"?properties=accumulations\"\n",
    "\n",
    "        # Full URL, endpt is defined up top\n",
    "        full_url = endpt + hist_ag_url + url_append\n",
    "        \n",
    "        if testing == False:\n",
    "        \n",
    "            # Get JSON\n",
    "            ag_norms_json = rq.get(full_url, headers=agro_header).json()\n",
    "            \n",
    "            return ag_norms_json\n",
    "            \n",
    "        elif testing == True:\n",
    "            \n",
    "            print(full_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:20:07.087441Z",
     "start_time": "2020-06-19T20:20:07.068494Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ppet(grid_df, start_date, end_date, drop_null=False, testing=False):\n",
    "    \"\"\"\n",
    "    Paraemeters\n",
    "    -----------\n",
    "    grid_df: Geopandas GeoDataFrame\n",
    "        Contains gridded area to fetch argonomics values for\n",
    "\n",
    "    start_date: string\n",
    "        Format \"YYYY-MM-DD\"\n",
    "\n",
    "    end_date: string\n",
    "        Format \"YYYY-MM-DD\"\n",
    "\n",
    "    drop_null: boolean (optional)\n",
    "        Drop grid cells that have null values returned from\n",
    "        API request for agronomics data. Often null values \n",
    "        result from grid cell lying in a body of water.\n",
    "\n",
    "    testing: boolean (optional)\n",
    "        Returns sample P/PET values for each grid cell \n",
    "        from 0 - 30 mm. Used for testing; bypasses API call.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid_df: Geopandas GeoDataFrame\n",
    "        Contains gridded input area with requested values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # For testing, generate random values for each cell\n",
    "    if testing == True:\n",
    "        grid_df['test_ppet'] = [np.random.randint(\n",
    "            0, 30) for i in range(0, grid.shape[0])]\n",
    "\n",
    "        return grid_df\n",
    "\n",
    "    # Add P/PET column if it does not exist and initialize to 0\n",
    "    if 'ppet' not in grid_df.columns:\n",
    "        grid_df = grid_df.assign(ppet=0)\n",
    "\n",
    "    # Iterate thru rows (cells) in gdf\n",
    "    for index, row in grid_df.iterrows():\n",
    "        \n",
    "        #Print progress\n",
    "        print(f\"On row {index + 1} of {grid.shape[0]}\")\n",
    "        \n",
    "        # Get centroid coordinates from each cell to pass to API\n",
    "        lat = round(row.geometry.centroid.y, 5)\n",
    "        lon = round(row.geometry.centroid.x, 5)\n",
    "\n",
    "        # Get JSON using call_api function\n",
    "        ag_norms_json = call_api(lat, lon, start_date, end_date)\n",
    "\n",
    "        # Try to pull data from return JSON\n",
    "        try:\n",
    "            \n",
    "            vals = ag_norms_json.get('accumulations').get('ppet')\n",
    "            \n",
    "            # Testing\n",
    "            if len(vals) == 0:\n",
    "                print(f\"Vals not returned for object number {row}\")\n",
    "            \n",
    "            grid_df.loc[index, 'ppet'] = vals \n",
    "\n",
    "        except:\n",
    "            grid_df.loc[index, 'ppet'] = np.nan\n",
    "\n",
    "        # Drop null cells if requested\n",
    "        if drop_null == True:\n",
    "            grid_df = grid_df[grid_df.ppet.isnull() == False]\n",
    "\n",
    "    return grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppet_grid = get_ppet(grid_df=grid,\n",
    "                     start_date=\"2020-04-01\",\n",
    "                     end_date=\"2020-04-30\",\n",
    "                     drop_null=False,\n",
    "                     testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:22:29.022901Z",
     "start_time": "2020-06-19T20:22:29.013923Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Add day range to this eventually\"\"\"\n",
    "def binary_threshold(gdf, daily_acc_ppet_threshold, month=None, year=None):\n",
    "\n",
    "    # Find monthly accumulated P/PET\n",
    "    #days_in_month = calendar.monthrange(year, month)[1]\n",
    "\n",
    "    # Calculate monthly accumulated P/PET based on user's threshold\n",
    "    #monthly_acc_ppet = days_in_month * daily_acc_ppet_threshold\n",
    "    monthly_acc_ppet = 30 * daily_acc_ppet_threshold\n",
    "\n",
    "    # Add Boolean flag column if meets threshold\n",
    "    gdf['meet_thresh'] = gdf['ppet'].apply(\n",
    "        lambda x: 1 if x <= monthly_acc_ppet else 0)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:38:39.917954Z",
     "start_time": "2020-06-19T20:38:39.909973Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_grid = binary_threshold(gdf=ppet_grid,\n",
    "                               daily_acc_ppet_threshold=0.2,\n",
    "                               month=4,\n",
    "                               year=2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T21:30:10.114929Z",
     "start_time": "2020-06-19T21:30:10.103958Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_convex_hull(gdf, crs):\n",
    "    \n",
    "    # Drop all rows that do not meet threshold\n",
    "    meet_thresh_only = gdf[gdf.meet_thresh == 1]\n",
    "    \n",
    "    # Dissolve polygons that meet threshold\n",
    "    meet_thresh_dissolve = meet_thresh_only.dissolve(by='meet_thresh')\n",
    "    \n",
    "    # Explode polygons so that there are unique contiguous areas\n",
    "    exploded = meet_thresh_dissolve.explode()\n",
    "\n",
    "    # Drop multi-index outer level generated from dissolve\n",
    "    exploded = exploded.droplevel(0)\n",
    "    \n",
    "    # Get largest polygon\n",
    "    largest = exploded[exploded.area == exploded.area.max()]\n",
    "    \n",
    "    # Generate convex hull\n",
    "    hull_largest = largest.convex_hull\n",
    "\n",
    "    # Convert to gdf\n",
    "    hull = gpd.GeoDataFrame(hull_largest, crs=gdf.crs)\n",
    "\n",
    "    # Rename column '0' to 'geometry'\n",
    "    hull.rename(columns={0:\"geometry\"}, inplace=True)\n",
    "    \n",
    "    return hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T21:30:10.460017Z",
     "start_time": "2020-06-19T21:30:10.393187Z"
    }
   },
   "outputs": [],
   "source": [
    "hull = to_convex_hull(binary_grid, 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T21:30:13.659696Z",
     "start_time": "2020-06-19T21:30:13.259941Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "hull.plot(ax=ax, color='none', edgecolor='red', zorder=4)\n",
    "binary_grid.plot(column='ppet', cmap='coolwarm_r', ax=ax, alpha=0.6, zorder=3)\n",
    "josephine.plot(color='green', alpha=0.9, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:13:18.626556Z",
     "start_time": "2020-06-19T20:13:17.952660Z"
    }
   },
   "outputs": [],
   "source": [
    "def proportional_split(grid_gdf, hull_gdf, crs):\n",
    "    \n",
    "    grid_gdf = grid_gdf.to_crs(f\"epsg:{crs}\")\n",
    "    \n",
    "    hull_gdf = hull_gdf.to_crs(f\"epsg:{crs}\")\n",
    "    \n",
    "    # Set summary variables to 0\n",
    "    inter_area_run_sum = 0\n",
    "    \n",
    "    # This is a list to more easily calculate average (using sum then len)\n",
    "    inter_ppet_run_sum = []\n",
    "    \n",
    "    for index, row in grid_gdf.iterrows():\n",
    "        \n",
    "        if row.geometry.intersects(hull_gdf.geometry[0]):\n",
    "            \n",
    "            intersect_area = row.geometry.intersection(hull_gdf.geometry[0]).area\n",
    "            \n",
    "            # Find the proportional split of grid cell's P/PET\n",
    "            proportional_ppet = (intersect_area / row.geometry.area) * row.ppet\n",
    "            \n",
    "            # Append it to the list\n",
    "            inter_ppet_run_sum.append(proportional_ppet)\n",
    "    \n",
    "    # Find average P/PET per cell\n",
    "    inter_ppet = round((sum(inter_ppet_run_sum) / len(inter_ppet_run_sum)), 3)\n",
    "    \n",
    "    print(f\"Total droughted area: {hull_gdf.geometry[0].area}\")\n",
    "\n",
    "    print(f\"Average P/PET in droughted area: {inter_ppet}\")\n",
    "    \n",
    "proportional_split(binary_grid, hull, \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T20:51:11.795154Z",
     "start_time": "2020-06-19T20:47:40.407126Z"
    }
   },
   "outputs": [],
   "source": [
    "start_year = 2010\n",
    "end_year = 2012\n",
    "start_day = \"04-01\"\n",
    "end_day = \"04-30\"\n",
    "\n",
    "# Calculate range of years\n",
    "years_range = np.arange(start_year, end_year + 1)\n",
    "\n",
    "# Create grid (does not change)\n",
    "grid = create_awhere_grid(aoi=josephine,\n",
    "                          out_crs='4236',\n",
    "                          calc_crs='2019')\n",
    "\n",
    "# Hold returned dfs for testing\n",
    "hulls_list = []\n",
    "\n",
    "for year in years_range:\n",
    "    # get grid\n",
    "    year_grid = grid\n",
    "\n",
    "    # Add P/PET values to entire grid\n",
    "    # Finctions calls API on centroid of each grid cell\n",
    "    year_grid_ppet = get_ppet(grid_df=year_grid,\n",
    "                              start_date=\"2020-04-01\",\n",
    "                              end_date=\"2020-04-30\",\n",
    "                              drop_null=False,\n",
    "                              testing=False)\n",
    "\n",
    "    # Reclassify grid using binary thresholding (1 = over threshold)\n",
    "    year_binary_grid = binary_threshold(gdf=year_grid_ppet,\n",
    "                                        daily_acc_ppet_threshold=0.2)\n",
    "    # Generate convex hull\n",
    "    year_convex_hull = to_convex_hull(year_binary_grid, 4326)\n",
    "    \n",
    "    hulls_list.append(year_convex_hull)\n",
    "    # (proportional split)\n",
    "    # add convex_hull, proportional_split as tuple\n",
    "\n",
    "# create gdf from returned_data with idx = year, geom=convex_hull, data=proportional_split\n",
    "# find centroids of hulls\n",
    "# plot centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-19T21:31:18.624569Z",
     "start_time": "2020-06-19T21:31:18.612605Z"
    }
   },
   "outputs": [],
   "source": [
    "hulls_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
