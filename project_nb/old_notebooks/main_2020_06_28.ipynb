{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "- Integrate Cale's aWhere grid script\n",
    "- auto-calculate day range for binary threshold\n",
    "- \"start_date\" and \"end_date\" need to be auto-formatted in main loop\n",
    "- change colors of final map\n",
    "- **overlay other data**\n",
    "- find Moran's i for binary_grid\n",
    "- comment functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:26.417117Z",
     "start_time": "2020-06-29T14:39:10.532836Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import calendar\n",
    "import datetime\n",
    "from datetime import date\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "\n",
    "import requests as rq\n",
    "\n",
    "# for aWhere API\n",
    "from header import AWhereAPI\n",
    "from secret_codes import *\n",
    "\n",
    "api_key = API_KEY\n",
    "api_secret = API_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:27.533927Z",
     "start_time": "2020-06-29T14:39:26.448306Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create aWhere object\n",
    "aw = AWhereAPI(api_key, api_secret)\n",
    "\n",
    "# To get auth token, encode secret and key\n",
    "sc = aw.encode_secret_and_key(API_KEY, API_SECRET)\n",
    "\n",
    "# Then call auth token\n",
    "token = aw.get_oauth_token(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:27.602927Z",
     "start_time": "2020-06-29T14:39:27.565045Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set variables for aWhere API call \n",
    "\n",
    "# General endpoint\n",
    "endpt = \"https://api.awhere.com\"\n",
    "\n",
    "# Set up headers: auth and specific header for agronomics data\n",
    "auth_headers = {\"Authorization\": \"Bearer %s\" % token,\n",
    "                \"Content-Type\": 'application/json'}\n",
    "\n",
    "agro_header = {\"Authorization\":  \"Bearer %s\" % token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:29.169312Z",
     "start_time": "2020-06-29T14:39:27.618427Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dphil\\Miniconda3\\envs\\earth-analytics-python\\lib\\site-packages\\pyproj\\crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n",
      "C:\\Users\\dphil\\Miniconda3\\envs\\earth-analytics-python\\lib\\site-packages\\pyproj\\crs.py:77: FutureWarning: '+init=<authority>:<code>' syntax is deprecated. '<authority>:<code>' is the preferred initialization method.\n",
      "  return _prepare_from_string(\" \".join(pjargs))\n"
     ]
    }
   ],
   "source": [
    "# Load areas of interest into gpd\n",
    "# Siskiyou is area of interest, Josephine is for testing API\n",
    "\n",
    "# Create path to home\n",
    "home = str(Path.home())\n",
    "\n",
    "# Create paths to geojsons since csvs make Jupyter crash\n",
    "path_to_josephine = os.path.join(\n",
    "    home, \"Desktop\", \"drought-tracker\", \"data\", \"TIGER\", \"josephine.geojson\")\n",
    "\n",
    "path_to_siskiyou = os.path.join(\n",
    "    home, \"Desktop\", \"drought-tracker\", \"data\", \"TIGER\", \"siskiyou.geojson\")\n",
    "\n",
    "# Create dfs with 1 county (Josephine is for testing)\n",
    "josephine = gpd.read_file(path_to_josephine)\n",
    "\n",
    "siskiyou = gpd.read_file(path_to_siskiyou)\n",
    "\n",
    "# Convert CRS\n",
    "josephine = josephine.to_crs(\"EPSG:4236\")\n",
    "\n",
    "siskiyou = siskiyou.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:53.403037Z",
     "start_time": "2020-06-29T14:39:53.371791Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_awhere_grid(aoi, out_crs, calc_crs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    aoi: Geopandas GeoDataFrame\n",
    "        One-element GeoDataFrame containing area over which\n",
    "        to draw grid\n",
    "    \n",
    "    out_crs: numeric string\n",
    "        String of EPSG code for exported GDF\n",
    "    \n",
    "    calc_crs: numeric string\n",
    "        String of EPSG code for CRS used\n",
    "        to calculate grid. CRS must have units of meters\n",
    "        to work with aWhere's API\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame containing 9km x 9km cells\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Reproject aoi to CRS using meters for aWhere grid cells\n",
    "    aoi = aoi.to_crs(f'EPSG:{calc_crs}')\n",
    "    \n",
    "    # Get x and y min and max from total boundaries\n",
    "    xmin, ymin, xmax, ymax = aoi.total_bounds\n",
    "    \n",
    "    # Set side of grid cell to 9 km\n",
    "    side = 9000\n",
    "    \n",
    "    # Create x values for x points for rows\n",
    "    x_range = np.arange(int(np.floor(xmin)), int(np.ceil(xmax)), side)\n",
    "    \n",
    "    # Create y values\n",
    "    y_range = np.arange(int(np.floor(ymin)), int(np.floor(ymax)), side)\n",
    "    \n",
    "    # Create empty list to hold grid cells\n",
    "    polygons = []\n",
    "    \n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            polygons.append(Polygon([(x,y), (x+side, y), (x+side, y+side), (x,y+side)]))\n",
    "            \n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons}, crs=f\"EPSG:{calc_crs}\")\n",
    "    \n",
    "    #grid.set_crs = f'EPSG:{calc_crs}'\n",
    "    \n",
    "    # Convert to out_crs\n",
    "    grid = grid.to_crs(f\"EPSG:{out_crs}\")\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:39:59.407791Z",
     "start_time": "2020-06-29T14:39:59.376652Z"
    }
   },
   "outputs": [],
   "source": [
    "def call_api(lat, lon, start_date, end_date, testing=False):\n",
    "    \n",
    "        # URL to historical agronomics (norms)\n",
    "        hist_ag_url = f\"/v2/agronomics/locations/{lat},{lon}/agronomicvalues/{start_date},{end_date}\"\n",
    "\n",
    "        # Endpoint suffix to get all accumulations\n",
    "        url_append = \"?properties=accumulations\"\n",
    "\n",
    "        # Full URL, endpt is defined up top\n",
    "        full_url = endpt + hist_ag_url + url_append\n",
    "        \n",
    "        if testing == False:\n",
    "        \n",
    "            # Get JSON\n",
    "            ag_norms_json = rq.get(full_url, headers=agro_header).json()\n",
    "            \n",
    "            # Testing            \n",
    "            return ag_norms_json\n",
    "            \n",
    "        elif testing == True:\n",
    "            \n",
    "            return full_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:40:10.878394Z",
     "start_time": "2020-06-29T14:40:10.847287Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ppet(ppet_grid_df, start_date, end_date, drop_null=False, testing=False):\n",
    "    \"\"\"\n",
    "    Paraemeters\n",
    "    -----------\n",
    "    grid_df: Geopandas GeoDataFrame\n",
    "        Contains gridded area to fetch argonomics values for\n",
    "\n",
    "    start_date: string\n",
    "        Format \"YYYY-MM-DD\"\n",
    "\n",
    "    end_date: string\n",
    "        Format \"YYYY-MM-DD\"\n",
    "\n",
    "    drop_null: boolean (optional)\n",
    "        Drop grid cells that have null values returned from\n",
    "        API request for agronomics data. Often null values \n",
    "        result from grid cell lying in a body of water.\n",
    "\n",
    "    testing: boolean (optional)\n",
    "        Returns sample P/PET values for each grid cell \n",
    "        from 0 - 30 mm. Used for testing; bypasses API call.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    grid_df: Geopandas GeoDataFrame\n",
    "        Contains gridded input area with requested values.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # Add P/PET column if it does not exist and set as float\n",
    "    if 'ppet' not in ppet_grid_df.columns:\n",
    "        ppet_grid_df = ppet_grid_df.assign(ppet=0.0)\n",
    "        \n",
    "    # For testing, generate random values for each cell\n",
    "    if testing == True:\n",
    "        ppet_grid_df['test_ppet'] = [np.random.randint(\n",
    "            0, 30) for i in range(0, grid.shape[0])]\n",
    "\n",
    "        return ppet_grid_df\n",
    "\n",
    "    print(\"Calling API for each cell...\")\n",
    "    # Iterate thru rows (cells) in gdf\n",
    "    for index, row in ppet_grid_df.iterrows():\n",
    "        \n",
    "        #Print progress\n",
    "        #print(f\"On row {index + 1} of {grid.shape[0]}\")\n",
    "        \n",
    "        # Get centroid coordinates from each cell to pass to API\n",
    "        lat = round(row.geometry.centroid.y, 5)\n",
    "        lon = round(row.geometry.centroid.x, 5)\n",
    "\n",
    "        # Get JSON using call_api function\n",
    "        ag_norms_json = call_api(lat, lon, start_date, end_date)\n",
    "        \n",
    "        # Try to pull data from return JSON\n",
    "        try:\n",
    "            \n",
    "            # Get \"PPET\" from JSON\n",
    "            vals = ag_norms_json.get('accumulations').get('ppet')\n",
    "            \n",
    "            # Round result to 3 decimal places\n",
    "            vals = round(vals, 3)\n",
    "            \n",
    "            # Add value to gdf\n",
    "            ppet_grid_df.at[index, 'ppet'] = vals \n",
    "    \n",
    "        except:\n",
    "            \n",
    "            ppet_grid_df.at[index, 'ppet'] = np.nan\n",
    "\n",
    "        # Drop null cells if requested\n",
    "        if drop_null == True:\n",
    "            ppet_grid_df = ppet_grid_df[ppet_grid_df.ppet.isnull() == False]\n",
    "\n",
    "    print(\"Grid with P/PET values generated.\")\n",
    "    \n",
    "    return ppet_grid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:40:14.265814Z",
     "start_time": "2020-06-29T14:40:14.234599Z"
    }
   },
   "outputs": [],
   "source": [
    "def binary_threshold(gdf, acc_ppet_threshold, start_date, end_date, year):\n",
    "    \n",
    "    # Convert start date into datetime object\n",
    "    start_day = int(start_date.split(\"-\")[1])\n",
    "    start_month = int(start_date.split(\"-\")[0])\n",
    "    start_date = date(year, start_month, start_day)\n",
    "\n",
    "    # Convert end date into datetime object\n",
    "    end_day = int(end_date.split(\"-\")[1])\n",
    "    end_month = int(end_date.split(\"-\")[0])\n",
    "    end_date = date(year, end_month, end_day)\n",
    "\n",
    "    # Find number of days of difference\n",
    "    time_delta = abs(end_date - start_date)\n",
    "    \n",
    "    # Get days from object\n",
    "    days_diff = time_delta.days\n",
    "\n",
    "    # Find accumulated P/PET threshold value \n",
    "    # based on user's input and time period\n",
    "    time_period_acc_ppet_thresh = days_diff * acc_ppet_threshold\n",
    "\n",
    "    # Add Boolean flag column if meets threshold\n",
    "    gdf['meet_thresh'] = gdf['ppet'].apply(\n",
    "        lambda x: 1 if x <= time_period_acc_ppet_thresh else 0)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:40:15.366661Z",
     "start_time": "2020-06-29T14:40:15.335513Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_convex_hull(gdf, crs):\n",
    "    \n",
    "    # Drop all rows that do not meet threshold\n",
    "    meet_thresh_only = gdf[gdf.meet_thresh == 1]\n",
    "    \n",
    "    # Dissolve polygons that meet threshold\n",
    "    meet_thresh_dissolve = meet_thresh_only.dissolve(by='meet_thresh')\n",
    "    \n",
    "    # Explode polygons so that there are unique contiguous areas\n",
    "    exploded = meet_thresh_dissolve.explode()\n",
    "\n",
    "    # Drop multi-index outer level generated from dissolve\n",
    "    exploded = exploded.droplevel(0)\n",
    "    \n",
    "    # Get largest polygon\n",
    "    largest = exploded[exploded.area == exploded.area.max()]\n",
    "    \n",
    "    # Generate convex hull\n",
    "    hull_largest = largest.convex_hull\n",
    "    \n",
    "    # Reset index so only item in gdf is in position [0]\n",
    "    hull_largest_out = hull_largest.reset_index(drop=True)\n",
    "\n",
    "    # Convert to gdf\n",
    "    #hull = gpd.GeoDataFrame(hull_largest, crs=gdf.crs)\n",
    "\n",
    "    # Rename column '0' to 'geometry'\n",
    "    #hull.rename(columns={0:\"geometry\"}, inplace=True)\n",
    "    \n",
    "    return hull_largest_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-29T14:40:16.215056Z",
     "start_time": "2020-06-29T14:40:16.183917Z"
    }
   },
   "outputs": [],
   "source": [
    "def proportional_split(grid_gdf, hull_gdf, crs):\n",
    "    \n",
    "    grid_gdf = grid_gdf.to_crs(f\"epsg:{crs}\")\n",
    "    \n",
    "    hull_gdf = hull_gdf.to_crs(f\"epsg:{crs}\")\n",
    "    \n",
    "    # Set summary variables to 0\n",
    "    inter_area_run_sum = 0\n",
    "    \n",
    "    # This is a list to more easily calculate average (using sum then len)\n",
    "    inter_ppet_run_sum = []\n",
    "    \n",
    "    for index, row in grid_gdf.iterrows():\n",
    "        \n",
    "        if row.geometry.intersects(hull_gdf.geometry[0]):\n",
    "            \n",
    "            intersect_area = row.geometry.intersection(hull_gdf.geometry[0]).area\n",
    "            \n",
    "            # Find the proportional split of grid cell's P/PET\n",
    "            proportional_ppet = (intersect_area / row.geometry.area) * row.ppet\n",
    "            \n",
    "            # Append it to the list\n",
    "            inter_ppet_run_sum.append(proportional_ppet)\n",
    "    \n",
    "    # Find average P/PET per cell\n",
    "    inter_ppet = round((sum(inter_ppet_run_sum) / len(inter_ppet_run_sum)), 3)\n",
    "    \n",
    "    # Find total droughted area\n",
    "    droughted_area = hull_gdf.geometry[0].area\n",
    "    \n",
    "    #print(f\"Average P/PET in droughted area: {inter_ppet}\")\n",
    "    \n",
    "    #print(f\"Total droughted area: {hull_gdf.geometry[0].area}\")\n",
    "\n",
    "    return inter_ppet, droughted_area\n",
    "    \n",
    "#proportional_split(binary_grid, hull, \"2019\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T15:53:19.857109Z",
     "start_time": "2020-06-26T15:24:18.503862Z"
    }
   },
   "outputs": [],
   "source": [
    "start_year = 2014\n",
    "end_year = 2019\n",
    "start_day = \"06-01\"\n",
    "end_day = \"10-30\"\n",
    "\n",
    "# Calculate range of years\n",
    "years_range = np.arange(start_year, end_year + 1)\n",
    "\n",
    "# Create grid (does not change with each iteration)\n",
    "aoi_grid = create_awhere_grid(aoi=siskiyou,\n",
    "                              out_crs='4236',\n",
    "                              calc_crs='2019')\n",
    "\n",
    "# Create list to hold rows (dicts) of values:\n",
    "# years, geoms, inferred P/PET, area of convex hull\n",
    "all_years_rows = []\n",
    "\n",
    "for year in years_range:\n",
    "\n",
    "    print(f\"On year {year}...\")\n",
    "\n",
    "    # Add P/PET values to entire grid\n",
    "    # Call API on centroid of each grid cell\n",
    "    year_grid_ppet = get_ppet(ppet_grid_df=aoi_grid,\n",
    "                              start_date=f\"{year}-{start_day}\",\n",
    "                              end_date=f\"{year}-{end_day}\",\n",
    "                              drop_null=False,\n",
    "                              testing=False)\n",
    "\n",
    "    # Reclassify grid using binary thresholding (1 = over threshold)\n",
    "    year_binary_grid = binary_threshold(gdf=year_grid_ppet,\n",
    "                                        acc_ppet_threshold=0.8,\n",
    "                                        start_date=start_day,\n",
    "                                        end_date=end_day,\n",
    "                                        year=year)\n",
    "\n",
    "    try:\n",
    "        # Generate convex hull\n",
    "        year_convex_hull_gdf = to_convex_hull(year_binary_grid, 4326)\n",
    "\n",
    "        # Convert into Shapely Polygon\n",
    "        year_convex_hull_poly = year_convex_hull_gdf[0]\n",
    "\n",
    "        # Proportional split (\"2019\" is CRS)\n",
    "        average_ppet, drought_area = proportional_split(\n",
    "            year_binary_grid, year_convex_hull_gdf, \"2019\")\n",
    "\n",
    "        # Add all info to dict for this year\n",
    "        year_dict = {\"year\": year,\n",
    "                     \"inferred_average_ppet\": average_ppet,\n",
    "                     \"droughted_area\": drought_area,\n",
    "                     \"geometry\": year_convex_hull_poly}\n",
    "\n",
    "        all_years_rows.append(year_dict)\n",
    "        \n",
    "    except: \n",
    "         year_dict = {\"year\": year,\n",
    "                     \"inferred_average_ppet\": None,\n",
    "                     \"droughted_area\": None,\n",
    "                     \"geometry\": None}\n",
    "\n",
    "# Create gdf from list of dicts, each representing a row\n",
    "gdf = gpd.GeoDataFrame(all_years_rows, crs=\"EPSG:4236\")\n",
    "\n",
    "# Set index to year\n",
    "gdf.set_index(\"year\", inplace=True)\n",
    "\n",
    "# Find centroids of hulls\n",
    "gdf['centroid'] = gdf.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T15:53:53.716257Z",
     "start_time": "2020-06-26T15:53:53.685004Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_lines(gdf):\n",
    "    \n",
    "    # List to hold lines for each year\n",
    "    all_years_lines = []\n",
    "    \n",
    "    # Loop through gdf\n",
    "    for index, row in gdf.iterrows():\n",
    "        \n",
    "        try:\n",
    "            # Get centroid from previous year\n",
    "            last_year_centroid = gdf.at[(index - 1), 'centroid']\n",
    "\n",
    "            # Get centroid from current year\n",
    "            this_year_centroid = gdf.at[index, 'centroid']\n",
    "\n",
    "            # Create line from centroid last year to centroid this year\n",
    "            year_line = LineString([last_year_centroid, this_year_centroid])\n",
    "\n",
    "        except:\n",
    "\n",
    "            # Print helpful message\n",
    "            print(f\"Skipping {index}...\")\n",
    "\n",
    "            # If no centroid data exists, skip\n",
    "            year_line = None\n",
    "\n",
    "        all_years_lines.append(year_line)\n",
    "        \n",
    "    return all_years_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T16:03:33.687793Z",
     "start_time": "2020-06-26T16:03:33.657563Z"
    }
   },
   "outputs": [],
   "source": [
    "all_years_lines = create_lines(gdf=gdf)\n",
    "gdf['linear_trend'] = all_years_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T16:03:36.238233Z",
     "start_time": "2020-06-26T16:03:36.220091Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf_lines = gdf.set_geometry(gdf.linear_trend)\n",
    "gdf_centroids = gdf.set_geometry(gdf.centroid)\n",
    "gdf_polys = gdf.set_geometry(gdf.geometry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T16:03:36.836878Z",
     "start_time": "2020-06-26T16:03:36.783490Z"
    }
   },
   "outputs": [],
   "source": [
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T18:26:57.235471Z",
     "start_time": "2020-06-26T18:26:56.871558Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "gdf_lines.plot(ax=ax, column=gdf_lines.index.values, cmap=\"Oranges\", legend=True)\n",
    "\n",
    "gdf_centroids.plot(ax=ax, cmap=\"Oranges\", alpha=0.7)\n",
    "\n",
    "#gdf_polys.plot(ax=ax, cmap=\"Oranges\", edgecolor=\"black\", alpha=0.2)\n",
    "\n",
    "siskiyou.plot(ax=ax, color='green', alpha=0.2, edgecolor=\"black\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T21:54:05.412707Z",
     "start_time": "2020-06-28T21:54:05.372811Z"
    }
   },
   "outputs": [],
   "source": [
    "path_to_gdf = os.path.join(home, \"Desktop\", \"drought-tracker\", \"data\", \"created\", \"siskiyou_tracked.geojson\")\n",
    "gdf = gpd.read_file(path_to_gdf)\n",
    "gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T21:56:49.971954Z",
     "start_time": "2020-06-28T21:56:49.639841Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rows = []\n",
    "for index, row in gdf.iterrows():\n",
    "    try:\n",
    "        # Get year\n",
    "        year = index\n",
    "\n",
    "        # Get extents\n",
    "        last_yr_extent = gdf.at[(index-1), \"geometry\"]\n",
    "        this_yr_extent = gdf.at[index, \"geometry\"]\n",
    "\n",
    "        # Find overlapping\n",
    "        inters = this_yr_extent.intersection(last_yr_extent)\n",
    "\n",
    "        y_dict = {\"year\": year,\n",
    "                  \"geometry\": inters}\n",
    "        \n",
    "        all_rows.append(y_dict)\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "overlaps_gdf = gpd.GeoDataFrame(all_rows)\n",
    "overlaps_gdf.plot(column='year', cmap='viridis', alpha=0.2, legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-28T21:58:38.391405Z",
     "start_time": "2020-06-28T21:58:38.381433Z"
    }
   },
   "outputs": [],
   "source": [
    "all_rows[4].get('geometry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.792967Z",
     "start_time": "2020-06-24T17:58:06.197Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "raise ValueError(\"Testing cells below\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-26T16:09:31.104125Z",
     "start_time": "2020-06-26T16:09:31.075957Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Exporting siskiyou for later use\n",
    "# Have to drop columns\n",
    "\n",
    "# Copy gdf\n",
    "gdf_out = gdf.copy()\n",
    "\n",
    "# Weird columns to drop\n",
    "drop_columns = ['centroid', 'linear_trend']\n",
    "\n",
    "# Drop columns\n",
    "gdf_out = gdf_out.drop(columns=drop_columns, inplace=True)\n",
    "\n",
    "# Create out path\n",
    "#gdf_out_path = os.path.join(home, \"Desktop\", \"drought-tracker\", \"data\", \"created\", \"siskiyou_tracked.geojson\")\n",
    "\n",
    "# Export\n",
    "#gdf_out.to_file(gdf_out_path, driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T19:11:53.524917Z",
     "start_time": "2020-06-24T19:11:53.105205Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set(title=\"Cumulative P/PET values, Summer 2019\\nSiskiyou County, OR\")\n",
    "\n",
    "year_binary_grid.plot(column='ppet', cmap='viridis_r', ax=ax, legend=True)\n",
    "\n",
    "josephine.plot(ax=ax, color='none', edgecolor='black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.795959Z",
     "start_time": "2020-06-24T17:58:06.201Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create grid polygon\n",
    "grid = create_awhere_grid(aoi=josephine,\n",
    "                          out_crs='4236',\n",
    "                          calc_crs='2019')\n",
    "\n",
    "# Add centroid column\n",
    "grid['centroid'] = grid.geometry.apply(lambda poly: poly.centroid)\n",
    "\n",
    "# Check to see if everything looks correct\n",
    "fig, ax = plt.subplots()\n",
    "grid.plot(color=\"none\", linewidth=1, edgecolor='orange', ax=ax, zorder=3)\n",
    "josephine.plot(color='green', zorder=2, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.798950Z",
     "start_time": "2020-06-24T17:58:06.204Z"
    }
   },
   "outputs": [],
   "source": [
    "ppet_grid_df = get_ppet(ppet_grid_df=grid,\n",
    "                        start_date=\"2020-04-01\",\n",
    "                        end_date=\"2020-04-30\",\n",
    "                        drop_null=False,\n",
    "                        testing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.801943Z",
     "start_time": "2020-06-24T17:58:06.208Z"
    }
   },
   "outputs": [],
   "source": [
    "binary_grid = binary_threshold(gdf=ppet_grid_df,\n",
    "                               daily_acc_ppet_threshold=0.2,\n",
    "                               month=4,\n",
    "                               year=2020)\n",
    "\n",
    "binary_grid[binary_grid.meet_thresh==1].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.804933Z",
     "start_time": "2020-06-24T17:58:06.210Z"
    }
   },
   "outputs": [],
   "source": [
    "hull = to_convex_hull(binary_grid, 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-24T18:01:37.806931Z",
     "start_time": "2020-06-24T17:58:06.214Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "hull.plot(ax=ax, color='none', edgecolor='red', zorder=4)\n",
    "binary_grid.plot(column='ppet', cmap='coolwarm_r', ax=ax, alpha=0.6, zorder=3)\n",
    "josephine.plot(color='green', alpha=0.9, ax=ax)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
