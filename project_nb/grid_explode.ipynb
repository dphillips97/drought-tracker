{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "- get stats for droughted area (convex hull):\n",
    " - spatial join convex hull with original grid with PPET values\n",
    " - get values for all 9km x 9km squares in hull\n",
    " - do proportional split on squares that don't lie 100% in convex hull\n",
    " - get area\n",
    "- get days over time period specified\n",
    "- get centroid for hull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:18.075049Z",
     "start_time": "2020-05-30T23:46:15.763826Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "import requests as rq\n",
    "\n",
    "# for aWhere API\n",
    "from header import AWhereAPI\n",
    "from secret_codes import *\n",
    "\n",
    "api_key = API_KEY\n",
    "api_secret = API_SECRET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:19.116559Z",
     "start_time": "2020-05-30T23:46:18.360761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create aWhere object\n",
    "aw = AWhereAPI(api_key, api_secret)\n",
    "\n",
    "# To get auth token, encode secret and key\n",
    "sc = aw.encode_secret_and_key(API_KEY, API_SECRET)\n",
    "\n",
    "# Then call auth token\n",
    "token = aw.get_oauth_token(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:19.483674Z",
     "start_time": "2020-05-30T23:46:19.459577Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Set variables for aWhere API call\"\"\"\n",
    "\n",
    "# General endpoint\n",
    "endpt = \"https://api.awhere.com\"\n",
    "\n",
    "# Set up headers: auth and specific header for agronomics data\n",
    "auth_headers = {\"Authorization\": \"Bearer %s\" % token,\n",
    "                \"Content-Type\": 'application/json'}\n",
    "\n",
    "agro_header = {\"Authorization\":  \"Bearer %s\" % token}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:47.070553Z",
     "start_time": "2020-05-30T23:46:46.449615Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create path to home\n",
    "home = str(Path.home())\n",
    "\n",
    "# Create path to geojson since csv crashes Jupyter\n",
    "path_to_marin = os.path.join(\n",
    "    home, \"Desktop\", \"drought-tracker\", \"data\", \"TIGER\", \"marin.geojson\")\n",
    "\n",
    "# Create df with 1 test county (Marin)\n",
    "marin = gpd.read_file(path_to_marin)\n",
    "\n",
    "marin = marin.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:20.349670Z",
     "start_time": "2020-05-30T23:46:20.336600Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_awhere_grid(aoi, out_crs, calc_crs):\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    aoi: Geopandas GeoDataFrame\n",
    "        One-element GeoDataFrame containing area over which\n",
    "        to draw grid\n",
    "    \n",
    "    out_crs: numeric string\n",
    "        String of EPSG code for exported GDF\n",
    "    \n",
    "    calc_crs: numeric string\n",
    "        String of EPSG code for CRS used\n",
    "        to calculate grid. CRS must have units of meters\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    GeoDataFrame containing 9km x 9km cells\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Reproject aoi to CRS using meters for aWhere grid cells\n",
    "    aoi = aoi.to_crs(f'epsg:{calc_crs}')\n",
    "    \n",
    "    # Get x and y min and max from total boundaries\n",
    "    xmin, ymin, xmax, ymax = aoi.total_bounds\n",
    "    \n",
    "    # Set side of grid cell to 9 km\n",
    "    side = 9000\n",
    "    \n",
    "    # Create x values for x points for rows\n",
    "    x_range = np.arange(int(np.floor(xmin)), int(np.ceil(xmax)), side)\n",
    "    \n",
    "    # Create y values\n",
    "    y_range = np.arange(int(np.floor(ymin)), int(np.floor(ymax)), side)\n",
    "    \n",
    "    # Create empty list to hold grid cells\n",
    "    polygons = []\n",
    "    \n",
    "    for x in x_range:\n",
    "        for y in y_range:\n",
    "            polygons.append(Polygon([(x,y), (x+side, y), (x+side, y+side), (x,y+side)]))\n",
    "            \n",
    "    grid = gpd.GeoDataFrame({'geometry': polygons})\n",
    "    \n",
    "    grid.crs = f'EPSG:{calc_crs}'\n",
    "    \n",
    "    # Convert to out_crs\n",
    "    grid = grid.to_crs(f\"EPSG:{out_crs}\")\n",
    "    \n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:46:52.424091Z",
     "start_time": "2020-05-30T23:46:50.849194Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create grid polygon\n",
    "grid = create_awhere_grid(aoi=marin,\n",
    "                          out_crs='4326',\n",
    "                          calc_crs='2019')\n",
    "\n",
    "# Add centroid column\n",
    "grid['centroid'] = grid.geometry.apply(lambda poly: poly.centroid)\n",
    "\n",
    "\n",
    "# Check to see if everything looks correct\n",
    "fig, ax = plt.subplots()\n",
    "grid.plot(color=\"none\", linewidth=0.2, edgecolor='red', ax=ax)\n",
    "marin.plot(color='steelblue', alpha=0.4, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:53:06.622134Z",
     "start_time": "2020-05-30T23:53:06.563513Z"
    }
   },
   "outputs": [],
   "source": [
    "for index, row in grid.iterrows():\n",
    "    print(round(row.centroid.x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-30T23:50:03.291490Z",
     "start_time": "2020-05-30T23:50:01.767680Z"
    }
   },
   "outputs": [],
   "source": [
    "# URL to historical agronomics (norms)\n",
    "hist_ag_url = f\"/v2/agronomics/locations/40,-105/agronomicvalues/2020-04-01,2020-05-30\"\n",
    "\n",
    "# Endpoint suffix to get all accumulations\n",
    "url_append = \"?properties=accumulations\"\n",
    "\n",
    "full_url = endpt + hist_ag_url + url_append\n",
    "\n",
    "ag_norms = rq.get(full_url, headers=agro_header)\n",
    "\n",
    "ag_norms_json = ag_norms.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T00:01:55.190588Z",
     "start_time": "2020-05-31T00:01:19.665470Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_ppet(grid_df, start_date, end_date):\n",
    "\n",
    "    if 'ppet' not in grid_df.columns:\n",
    "        grid_df = grid_df.assign(ppet=0)\n",
    "\n",
    "    for index, row in grid_df.iterrows():\n",
    "\n",
    "        # Get centroid coordinates from grid_df\n",
    "        lat = round(row.centroid.y, 5)\n",
    "        lon = round(row.centroid.x, 5)\n",
    "\n",
    "        # URL to historical agronomics (norms)\n",
    "        hist_ag_url = f\"/v2/agronomics/locations/{lat},{lon}/agronomicvalues/{start_date},{end_date}\"\n",
    "\n",
    "        # Endpoint suffix to get all accumulations\n",
    "        url_append = \"?properties=accumulations\"\n",
    "\n",
    "        # Full URL\n",
    "        full_url = endpt + hist_ag_url + url_append\n",
    "\n",
    "        # Get JSON\n",
    "        ag_norms_json = rq.get(full_url, headers=agro_header).json()\n",
    "        \n",
    "        try:\n",
    "            grid_df.loc[index, 'ppet'] = ag_norms_json.get('accumulations').get('ppet')\n",
    "            \n",
    "        except:\n",
    "            grid_df.loc[index, 'ppet'] = np.nan\n",
    "            \n",
    "    return grid_df\n",
    "\n",
    "ppet_grid = get_ppet(grid, \"2020-04-01\", \"2020-04-30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T00:02:07.933794Z",
     "start_time": "2020-05-31T00:02:07.363532Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ppet_grid.plot(column='ppet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T00:33:26.594020Z",
     "start_time": "2020-05-31T00:33:26.562909Z"
    }
   },
   "outputs": [],
   "source": [
    "ppet_grid_vals = ppet_grid[ppet_grid.ppet.isnull() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-31T00:33:42.299811Z",
     "start_time": "2020-05-31T00:33:42.052450Z"
    }
   },
   "outputs": [],
   "source": [
    "ppet_grid_vals.plot(column=\"ppet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:24.787727Z",
     "start_time": "2020-05-24T19:39:24.763462Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate random values for each cell and add to grid gdf\n",
    "grid['test_ppet'] = [np.random.randint(0,30) for i in range(0, grid.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:26.314855Z",
     "start_time": "2020-05-24T19:39:26.299673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Allow user to change threshold as daily value\n",
    "daily_accumulated_ppet = 0.5\n",
    "\n",
    "# Calculate monthly value\n",
    "monthly_accumulated_ppet = daily_accumulated_ppet * 30\n",
    "\n",
    "# Calcualte if PPET meets threshold and add Boolean flag\n",
    "grid['meet_thresh'] = grid['test_ppet'].apply(lambda x: 1 if x >= monthly_accumulated_ppet else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:27.952837Z",
     "start_time": "2020-05-24T19:39:27.794936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Drop all rows that do not meet threshold\n",
    "droughted = grid[grid.meet_thresh == 1]\n",
    "\n",
    "# Dissolve polygons\n",
    "drought_dissolve = droughted.dissolve(by='meet_thresh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:29.407978Z",
     "start_time": "2020-05-24T19:39:29.365507Z"
    }
   },
   "outputs": [],
   "source": [
    "# Explode polygons so that there are unique contiguous areas\n",
    "exploded = drought_dissolve.explode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:30.855620Z",
     "start_time": "2020-05-24T19:39:30.844423Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add area column\n",
    "exploded[\"sqkm\"] = exploded['geometry'].area/ 10**6\n",
    "\n",
    "# Drop multi-index outer level generated from dissolve\n",
    "exploded = exploded.droplevel(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:32.440291Z",
     "start_time": "2020-05-24T19:39:32.426935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get largest polygon\n",
    "largest = exploded[exploded.sqkm == exploded.sqkm.max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:41.071262Z",
     "start_time": "2020-05-24T19:39:41.061629Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate convex hull\n",
    "hull_largest = largest.convex_hull\n",
    "\n",
    "# Convert to gdf\n",
    "hull = gpd.GeoDataFrame(hull_largest, crs='epsg:2019')\n",
    "\n",
    "# Rename column '0' to 'geometry'\n",
    "hull.rename(columns={0:\"geometry\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-24T19:39:59.421104Z",
     "start_time": "2020-05-24T19:39:58.978859Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "\n",
    "exploded.plot(ax=ax, column='sqkm')\n",
    "#largest.plot(ax=ax)\n",
    "#largest_envelope.plot(ax=ax, alpha=0.2)\n",
    "#simple_largest.plot(ax=ax, alpha=0.4, color='orange')\n",
    "hull.plot(ax=ax, alpha=0.4)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
